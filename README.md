# BET - Bi-Encoder Toolkit

BET (Bi-Encoder Toolkit) is a flexible framework that provides an efficient implementation of Bi-Encoder models using PyTorch Lightning. The toolkit is designed to facilitate the training and usage of Bi-Encoder models for various applications. While the main implementation focuses on entity linking (achieving state-of-the-art results), the architecture and design of BET enable its application in a wide range of tasks that benefit from dense vector representations and efficient data retrieval.

## Features

- Efficient implementation of Bi-Encoder models using PyTorch Lightning
- Modular and flexible codebase for easy customization and extension
- Support for diverse applications leveraging dense vector representations
- Ability to train and fine-tune models with any base model and language
- Usage of SCANN for efficient similarity search and nearest neighbor retrieval

## Architecture

BET's core architecture revolves around the Bi-Encoder model. It consists of two separate encoders: one for queries and another for the input data (e.g., abstracts of Wikipedia pages). The encoders map the input text to dense vector representations, which capture semantic information and similarities between different texts.

The framework leverages the power of PyTorch Lightning to efficiently train and manage the Bi-Encoder models. PyTorch Lightning provides a high-level interface for organizing the training loop, handling distributed training, and simplifying the process of adding custom functionality to the models.

## Usage

To use BET for your application, follow these steps:

1. Install the required dependencies:

   ```bash
   pip install -r requirements.txt
   ```

2. Clone the BET repository:

   ```bash
   git clone https://github.com/giovani-merlin/BET.git
   ```

3. Customize the codebase to fit your specific task. BET's modular design allows you to easily modify and extend the framework to suit your needs. You can integrate your own datasets, fine-tune the base models, or incorporate additional functionality.

4. Prepare your data and define the necessary preprocessing steps. Ensure that your data is compatible with the Bi-Encoder model's input requirements.

5. Train and evaluate the Bi-Encoder models using the provided training scripts. You can configure the hyperparameters, optimizer, and training settings according to your preferences.

6. Utilize the trained models for your desired applications. The dense vector representations generated by the Bi-Encoder models can be employed in various downstream tasks, such as entity linking, information retrieval, and similarity matching.

7. Experiment with different base models and languages. BET allows you to utilize any base model supported by PyTorch and adapt the framework to different languages, enabling efficient and effective utilization of dense vector representations across diverse applications.

## Resources

BET builds upon the advancements and insights from BLINK by Facebook and Google dense entity representations. You can leverage pre-trained models and resources from these projects to enhance your results and stay at the cutting edge of entity linking and related tasks.

## Contributing

We welcome contributions to BET from the open-source community. If you have ideas, bug fixes, or enhancements, please feel free to submit a pull request or open an issue on the GitHub repository.

## License

BET is released under the [MIT License](LICENSE). Feel free to use, modify, and distribute the framework according to the terms of the license.

# Problems

1. To encode all the candidates using the script "wbdsm_benchmark.py" I recommend to turn on NVIDIA performance mode. I don't know why but when using "on Demand" in the middle of the scripts the clock of the GPU goes down and the encoding process turns to be very slow.

## Keep cuda performance

   ```bash
   sudo nvidia-smi -pm 1
   ```

sudo apt install libcairo2-dev libgirepository1.0-dev meson  gnome-shell-extension-appindicator ninja-build appstream-util gir1.2-appindicator3-0.1 libdazzle-1.0-dev python3-cairo-dev

# FIX

EVALUATION ON TRAINING -> Have multiple times the correct candidate...This gives this great wrong result. But can be later......zeshel is already great and true (full eval is good)
